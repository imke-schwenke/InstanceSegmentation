{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Mask R-CNN Model with COCO Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 16:24:08.639344: W tensorflow/c/c_api.cc:304] Operation '{name:'res4b_branch2c_7/bias/Assign' id:70036 op device:{requested: '', assigned: ''} def:{{{node res4b_branch2c_7/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](res4b_branch2c_7/bias, res4b_branch2c_7/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import mrcnn.model as modellib\n",
    "import os\n",
    "\n",
    "# Define the paths to your dataset and model\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'dataset')\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_VAL_ANNOTATIONS = os.path.join(DATA_DIR, 'val', 'annotations.json')\n",
    "\n",
    "# Initialize COCO validation dataset\n",
    "coco = COCO(COCO_VAL_ANNOTATIONS)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Load validation dataset\n",
    "dataset_val = cElegans.CElegansDataset()\n",
    "dataset_val.load_c_elegans(DATA_DIR, \"val\")  # Load validation data\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Load the pre-trained Mask R-CNN model in inference mode\n",
    "class InferenceConfig(cElegans.CElegansConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5 \n",
    "\n",
    "\n",
    "config = InferenceConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Load the weights from the trained model\n",
    "model.load_weights('mask_rcnn_custom.h5', by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert Mask R-CNN detection results to COCO format\n",
    "def format_coco_result(image_id, r):\n",
    "    results = []\n",
    "    for i in range(len(r['class_ids'])):\n",
    "        y1, x1, y2, x2 = r['rois'][i]\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        # Ensure the width and height are positive\n",
    "        if w > 0 and h > 0:\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": int(r['class_ids'][i]),\n",
    "                \"bbox\": [float(x1), float(y1), float(w), float(h)],\n",
    "                \"score\": float(r['scores'][i])\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/keras/src/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2024-09-10 15:01:31.899886: W tensorflow/c/c_api.cc:304] Operation '{name:'bn4t_branch2c_4/beta/Assign' id:44718 op device:{requested: '', assigned: ''} def:{{{node bn4t_branch2c_4/beta/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](bn4t_branch2c_4/beta, bn4t_branch2c_4/beta/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2024-09-10 15:01:37.330492: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -308 } dim { size: -309 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -19 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -19 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.330582: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -298 } dim { size: -299 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -22 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -22 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.330649: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -286 } dim { size: -287 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -24 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -24 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.330772: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -272 } dim { size: -273 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -26 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 7 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -26 } dim { size: 7 } dim { size: 7 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.335860: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -308 } dim { size: -309 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -34 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -34 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.335939: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -298 } dim { size: -299 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -36 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -36 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.336007: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -286 } dim { size: -287 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -38 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -38 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n",
      "2024-09-10 15:01:37.336107: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -272 } dim { size: -273 } dim { size: 256 } } } inputs { dtype: DT_FLOAT shape { dim { size: -40 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -40 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 2300 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 6291456 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -40 } dim { size: 14 } dim { size: 14 } dim { size: 256 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   46.00000  max:  158.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   54.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  176.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   72.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  159.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   55.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   50.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    2.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    2.00000  max:  150.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   46.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   52.00000  max:  156.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  150.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   46.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   50.00000  max:  156.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  160.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   56.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    8.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   44.00000  max:  156.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  163.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   59.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   48.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  175.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   71.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  150.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   46.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   43.00000  max:  156.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    9.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   51.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    8.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    9.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    2.00000  max:  151.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   47.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    1.00000  max:  150.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   46.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  159.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   55.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:   50.00000  max:  157.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    3.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n",
      "Processing 1 images\n",
      "image                    shape: (1012, 1012, 3)       min:    4.00000  max:  161.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   57.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  int64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.17695  max:    1.11439  float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_id \u001b[38;5;129;01min\u001b[39;00m image_ids:\n\u001b[1;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m dataset_val\u001b[38;5;241m.\u001b[39mload_image(image_id)\n\u001b[0;32m----> 7\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     coco_results \u001b[38;5;241m=\u001b[39m format_coco_result(image_id, r)\n\u001b[1;32m      9\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(coco_results)\n",
      "File \u001b[0;32m~/Desktop/Uni/master/4. Semester/Computer Vision/InstanceSegmentation/mrcnn/model.py:2545\u001b[0m, in \u001b[0;36mMaskRCNN.detect\u001b[0;34m(self, images, verbose)\u001b[0m\n\u001b[1;32m   2542\u001b[0m     log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manchors\u001b[39m\u001b[38;5;124m\"\u001b[39m, anchors)\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;66;03m# Run object detection\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m detections, _, _, mrcnn_mask, _, _, _ \u001b[38;5;241m=\u001b[39m\\\n\u001b[0;32m-> 2545\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmolded_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;66;03m# Process detections\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/keras/src/engine/training_v1.py:1059\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1058\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/keras/src/engine/training_arrays_v1.py:801\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.predict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[1;32m    798\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[1;32m    799\u001b[0m     x, check_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39msteps\n\u001b[1;32m    800\u001b[0m )\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/keras/src/engine/training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[1;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/keras/src/backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4601\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4605\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m   4606\u001b[0m ):\n\u001b[1;32m   4607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4609\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[1;32m   4611\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4612\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4613\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   4614\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4615\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cv_env/lib/python3.9/site-packages/tensorflow/python/client/session.py:1482\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1481\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1482\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1485\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1486\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Perform inference on each image and save results in COCO format\n",
    "results = []\n",
    "for image_id in image_ids:\n",
    "    image = dataset_val.load_image(image_id)\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "    coco_results = format_coco_result(image_id, r)\n",
    "    results.extend(coco_results)\n",
    "\n",
    "# Save the detection results to a JSON file\n",
    "with open('detection_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.08s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.42s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "cocoGt = COCO(COCO_VAL_ANNOTATIONS)  \n",
    "cocoDt = cocoGt.loadRes('detection_results.json') \n",
    "\n",
    "coco_eval = COCOeval(cocoGt, cocoDt, 'bbox')  # Use 'segm' if evaluating masks\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
