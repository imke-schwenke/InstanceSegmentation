{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN and U-Net Model\n",
    "In the following notebook, we create a model based on mask rcnn (https://github.com/akTwelve/Mask_RCNN/tree/d9f01dcd83b1e90e5ea0b4b6d5ba753770e114ac).\n",
    "However, it will be combined with U-Net. In this way, we hope to combine the strenghts of both model and improve the instance segmentation of C Elegans.\n",
    "To do so, we will use the Encoder of U-Net as the Backbone of Mask RCNN instead of ResNet. This part is responsible for extraxting features out of images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.utils' has no attribute 'generic_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUNetEncoder\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, backbone_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet34\u001b[39m\u001b[38;5;124m'\u001b[39m, encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Programmieren/InstanceSegmentation/.venv/lib/python3.9/site-packages/segmentation_models/__init__.py:98\u001b[0m\n\u001b[1;32m     96\u001b[0m _framework \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSM_FRAMEWORK\u001b[39m\u001b[38;5;124m'\u001b[39m, _DEFAULT_KERAS_FRAMEWORK)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mset_framework\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_framework\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     other \u001b[38;5;241m=\u001b[39m _TF_KERAS_FRAMEWORK_NAME \u001b[38;5;28;01mif\u001b[39;00m _framework \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME \u001b[38;5;28;01melse\u001b[39;00m _KERAS_FRAMEWORK_NAME\n",
      "File \u001b[0;32m~/Programmieren/InstanceSegmentation/.venv/lib/python3.9/site-packages/segmentation_models/__init__.py:68\u001b[0m, in \u001b[0;36mset_framework\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _KERAS_FRAMEWORK_NAME:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mefficientnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m  \u001b[38;5;66;03m# init custom objects\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _TF_KERAS_FRAMEWORK_NAME:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/Programmieren/InstanceSegmentation/.venv/lib/python3.9/site-packages/efficientnet/keras.py:17\u001b[0m\n\u001b[1;32m     13\u001b[0m EfficientNetB7 \u001b[38;5;241m=\u001b[39m inject_keras_modules(model\u001b[38;5;241m.\u001b[39mEfficientNetB7)\n\u001b[1;32m     15\u001b[0m preprocess_input \u001b[38;5;241m=\u001b[39m inject_keras_modules(model\u001b[38;5;241m.\u001b[39mpreprocess_input)\n\u001b[0;32m---> 17\u001b[0m \u001b[43minit_keras_custom_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Programmieren/InstanceSegmentation/.venv/lib/python3.9/site-packages/efficientnet/__init__.py:71\u001b[0m, in \u001b[0;36minit_keras_custom_objects\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model\n\u001b[1;32m     66\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswish\u001b[39m\u001b[38;5;124m'\u001b[39m: inject_keras_modules(model\u001b[38;5;241m.\u001b[39mget_swish)(),\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedDropout\u001b[39m\u001b[38;5;124m'\u001b[39m: inject_keras_modules(model\u001b[38;5;241m.\u001b[39mget_dropout)()\n\u001b[1;32m     69\u001b[0m }\n\u001b[0;32m---> 71\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneric_utils\u001b[49m\u001b[38;5;241m.\u001b[39mget_custom_objects()\u001b[38;5;241m.\u001b[39mupdate(custom_objects)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'generic_utils'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models as sm\n",
    "\n",
    "class UNetEncoder(tf.keras.Model):\n",
    "    def __init__(self, backbone_name='resnet34', encoder_weights='imagenet'):\n",
    "        super(UNetEncoder, self).__init__()\n",
    "        self.unet = sm.Unet(backbone_name=backbone_name, encoder_weights=encoder_weights)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Durchlaufe das Modell und extrahiere die Encoder-Feature-Maps\n",
    "        encoder_outputs = self.unet.encoder(inputs)\n",
    "        return encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# root directory of the project\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ROOT_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive/MyDrive/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualize\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmrcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_images\n",
      "File \u001b[0;32m~/Programmieren/InstanceSegmentation/mrcnn/utils.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "# root directory of the project\n",
    "ROOT_DIR = '/content/gdrive/MyDrive/'\n",
    "\n",
    "import mrcnn.utils\n",
    "import mrcnn.visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import mrcnn.CElegansDataset\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mrcnn/mask_rcnn_coco.h5\")\n",
    "from mrcnn.cElegans import CElegansConfig\n",
    "config = CElegansConfig()\n",
    "CELEGANS_DIR = os.path.join(ROOT_DIR, \"dataset\")\n",
    "\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same\n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "\n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "from mrcnn.cElegans import CElegansDataset\n",
    "\n",
    "# Load Training dataset\n",
    "dataset = CElegansDataset()\n",
    "dataset.load_c_elegans(CELEGANS_DIR, \"train\")\n",
    "dataset.prepare()\n",
    "\n",
    "# Load validation dataset\n",
    "datatset_val = CElegansDataset()\n",
    "datatset_val.load_c_elegans(CELEGANS_DIR, \"val\")\n",
    "datatset_val.prepare()\n",
    "\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n",
    "print(\"Images: {}\\nClasses: {}\".format(len(datatset_val.image_ids), datatset_val.class_names))\n",
    "\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mrcnn/mask_rcnn_coco.h5\")\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)\n",
    "\n",
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset, datatset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=1,\n",
    "            layers='heads')\n",
    "\n",
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also\n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset, datatset_val,\n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2,\n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
